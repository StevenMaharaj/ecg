{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08360284464692334"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from ECG.ecg import read_ecg\n",
    "from ECG.ecg_sig import band_pass_filter\n",
    "from ECG.ecg import make_df_summary\n",
    "# file  =  os.path.join(os.path.dirname(os.path.realpath(__file__)),\"a01.dat\")\n",
    "# filer  =  os.path.join(os.path.dirname(os.path.realpath(__file__)),\"a01r.dat\")\n",
    "\n",
    "file  =  \"a01.dat\"\n",
    "filer  =  \"a01r.dat\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "data1 = pd.read_csv(\"freq_DT_Ampli_freqa1.csv\")\n",
    "data2 = pd.read_csv(\"freq_DT_Ampli_freqa2.csv\")\n",
    "data3 = pd.read_csv(\"freq_DT_Ampli_freqa3.csv\")\n",
    "data4 = pd.read_csv(\"freq_DT_Ampli_freqa4.csv\")\n",
    "data = pd.concat([data1,data2,data3,data4])\n",
    "data = data.drop(\"Unnamed: 0\",1)\n",
    "data[\"Amplitude\"] = data[\"Amplitude\"]/data[\"Amplitude\"].max()\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "y = data[\"Freqr\"].values\n",
    "# X = data.drop('Freqr',1).values\n",
    "X = data.drop(['Freqr',\"Amplitude\"],1).values\n",
    "# X = data.drop(['Freq','Freqr',\"Amplitude\"],1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, random_state=42)\n",
    "clf = SVR(gamma='scale', C=1.0, epsilon=0.1,kernel='rbf')\n",
    "clf.fit(X_train, y_train) \n",
    "clf.predict(X_test)\n",
    "mean_absolute_error(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': array([0.01      , 0.03020408, 0.05040816, 0.07061224, 0.09081633,\n",
       "       0.11102041, 0.13122449, 0.15142857, 0.17163265, 0.191836...\n",
       "       0.61612245, 0.63632653, 0.65653061, 0.67673469, 0.69693878,\n",
       "       0.71714286, 0.73734694, 0.75755102, 0.7777551 , 0.79795918,\n",
       "       0.81816327, 0.83836735, 0.85857143, 0.87877551, 0.89897959,\n",
       "       0.91918367, 0.93938776, 0.95959184, 0.97979592, 1.        ]),\n",
       "                         'gamma': [0.001, 0.005, 0.1, 1],\n",
       "                         'kernel': ('linear', 'rbf', 'poly')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search the SVM\n",
    "svr = SVR()\n",
    "parameters = {'kernel':('linear', 'rbf',\"poly\"), \n",
    "              'C':np.linspace(0.01,1,50),\n",
    "#              'epsilon': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "            'gamma': [ 0.001, 0.005, 0.1, 1]\n",
    "             }\n",
    "grid = GridSearchCV(svr, parameters, cv=5,n_jobs=-1)\n",
    "grid.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': array([0.01      , 0.03020408, 0.05040816, 0.07061224, 0.09081633,\n",
       "       0.11102041, 0.13122449, 0.15142857, 0.17163265, 0.191836...\n",
       "       0.61612245, 0.63632653, 0.65653061, 0.67673469, 0.69693878,\n",
       "       0.71714286, 0.73734694, 0.75755102, 0.7777551 , 0.79795918,\n",
       "       0.81816327, 0.83836735, 0.85857143, 0.87877551, 0.89897959,\n",
       "       0.91918367, 0.93938776, 0.95959184, 0.97979592, 1.        ]),\n",
       "                         'gamma': [0.001, 0.005, 0.1, 1],\n",
       "                         'kernel': ('linear', 'rbf', 'poly')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08360284464692334"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
    "                           epsilon=0.1, gamma='scale', kernel='rbf',\n",
    "                           max_iter=-1, shrinking=True, tol=0.001,\n",
    "                           verbose=False)\n",
    "clf.fit(X_train, y_train) \n",
    "clf.predict(X_test)\n",
    "mean_absolute_error(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maharaj/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                             max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators='warn', n_jobs=None,\n",
       "                                             oob_score=False, random_state=Non...\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "       196, 197, 198, 199])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # grid search the Random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(criterion='mse')\n",
    "parameters = {\n",
    "              'max_depth':np.arange(1,20),\n",
    "              'n_estimators':np.arange(1,200),\n",
    "             }\n",
    "grid = GridSearchCV(rf, parameters, cv=5,n_jobs=-1)\n",
    "grid.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/Users/maharaj/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 190 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   45.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators='warn',\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_sta...\n",
       "                                        'max_depth': [1, 5, 10, 15, 20, 25, 30,\n",
       "                                                      35, 40, 45, 50, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [20, 40, 60, 80, 100,\n",
       "                                                         120, 140, 160, 180,\n",
       "                                                         200, 220, 240, 260,\n",
       "                                                         280, 300, 320, 340,\n",
       "                                                         360, 380, 400, 420,\n",
       "                                                         440, 460, 480, 500,\n",
       "                                                         520, 540, 560, 580,\n",
       "                                                         600, ...]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 1000, num = 50)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(1, 50, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=1,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=4, min_samples_split=5,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=840,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08259770920362361"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_post_grid = rf_random.best_estimator_\n",
    "fr_post_grid.fit(X_train, y_train)\n",
    "fr_post_grid.predict(X_test)\n",
    "mean_absolute_error(y_test,fr_post_grid.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
